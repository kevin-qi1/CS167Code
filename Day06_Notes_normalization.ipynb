{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day06_Notes_normalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Code/blob/main/Day06_Notes_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUD6F9dEDkvY"
      },
      "source": [
        "# Day 06 Notes: Missing Data and Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3CV1zuLDiMj"
      },
      "source": [
        "## Missing Data Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZWmHrG-elX5"
      },
      "source": [
        "import pandas\n",
        "import numpy\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the data and take a look at it\n",
        "#You'll have to change this file path to get this line to work\n",
        "titanic = pandas.read_csv('/content/drive/MyDrive/CS167Spring22/datasets/titanic.csv')\n",
        "titanic.isna() #this returns a boolean that is True if data is NaN"
      ],
      "metadata": {
        "id": "bi6-UcdUj0Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMwVF2PXDXl3"
      },
      "source": [
        "titanic.isna().any() #will return a list of columns and whether or not they have missing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy_nYAavFM-s"
      },
      "source": [
        "### dropna()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k-7fmMsDffn"
      },
      "source": [
        "print(\"before: \", titanic.shape)\n",
        "clean_titanic = titanic.dropna()\n",
        "print(\"after: \", clean_titanic.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohw_amlQE3zI"
      },
      "source": [
        "print(\"before: \", titanic.shape)\n",
        "titanic.dropna(inplace=True)\n",
        "print(\"after: \", clean_titanic.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxit_xMxFQzr"
      },
      "source": [
        "### fillna()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CbqS1EEFGh4"
      },
      "source": [
        "# let's reload the data so that we have missing data again.\n",
        "titanic = pandas.read_csv('/content/drive/MyDrive/CS167/datasets/titanic.csv')\n",
        "\n",
        "#and fill the missing data this time.\n",
        "\n",
        "print(\"before: \", titanic['age'].isna().any())\n",
        "age_mean = titanic['age'].mean()\n",
        "titanic['age'].fillna(age_mean, inplace=True)\n",
        "print(\"after: \", titanic['age'].isna().any())\n",
        "titanic.head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Programming Exercise #1\n",
        "### Load in the dataset MoviesData.csv (the dataset used in Notebook #1)\n",
        "1. What is the shape of the data frame?\n",
        "2. Which of the columns have data that is missing?\n",
        "3. Change all of the NaN values in the column IMDb to the average of column IMDb\n",
        "4. Verify that the column no longer has any missing data.\n",
        "5. Remove all rows that have NaN values in any of the other columns\n",
        "6. What is the final shape?"
      ],
      "metadata": {
        "id": "8eeJb5-Ok0Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the dataset MoviesData.csv\n",
        "movies = pandas.read_csv('/content/drive/MyDrive/CS167Spring22/datasets/MoviesData.csv')"
      ],
      "metadata": {
        "id": "3Cvzlbzplf27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. What is the shape of the data frame?"
      ],
      "metadata": {
        "id": "10B77e7mnCXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Which of the columns have data that is missing?"
      ],
      "metadata": {
        "id": "PfwIAuSKnJgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.Change all of the NaN values in the column IMDb to the average of column IMDb"
      ],
      "metadata": {
        "id": "z7Jh1ZYwnQxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Verify that the column no longer has any missing data."
      ],
      "metadata": {
        "id": "dOralSWvnowF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Remove all rows that have NaN values in any of the other columns"
      ],
      "metadata": {
        "id": "AfxKxPv0n0-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. What is the final shape?"
      ],
      "metadata": {
        "id": "pV-rPMDpoxq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqW5Kho2fUCf"
      },
      "source": [
        "## Normalization Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXX5sRQJe-hi"
      },
      "source": [
        "titanic = pandas.read_csv('/content/drive/MyDrive/CS167/datasets/titanic.csv')\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfr_atmVfpWX"
      },
      "source": [
        "#convert sex to numeric\n",
        "titanic['sex'] = titanic['sex'].replace(to_replace='female', value=1)\n",
        "titanic['sex'] = titanic['sex'].replace(to_replace='male', value=0)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd8hkl5IfshH"
      },
      "source": [
        "#gender\n",
        "#calculate mean and std\n",
        "s_mean = titanic['sex'].mean()\n",
        "s_std = titanic['sex'].std()\n",
        "\n",
        "#replace column with each entry's z-score\n",
        "titanic['sex'] = (titanic[\"sex\"] - s_mean)/s_std\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s3luwptfuq6"
      },
      "source": [
        "#age\n",
        "#calculate mean and std\n",
        "a_mean = titanic['age'].mean()\n",
        "a_std = titanic['age'].std()\n",
        "\n",
        "#replace column with each entry's z-score\n",
        "titanic['age'] = (titanic[\"age\"] - a_mean)/a_std\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mS9rbmqHdPc"
      },
      "source": [
        "## kNN Functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8TRZjigHMBF"
      },
      "source": [
        "import numpy\n",
        "\n",
        "def knn(specimen, data, k):\n",
        "  data_copy = data.copy()\n",
        "  data_copy['distance_to_new'] = numpy.sqrt(\n",
        "    (specimen['petal length']-data['petal length'])**2\n",
        "    +(specimen['sepal length']-data['sepal length'])**2\n",
        "    +(specimen['petal width']-data['petal width'])**2\n",
        "    +(specimen['sepal width']-data['sepal width'])**2)\n",
        "  \n",
        "  sorted_data = data_copy.sort_values(['distance_to_new']) \n",
        "  return sorted_data.iloc[0:k]['species'].mode()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYESMJwtHRYN"
      },
      "source": [
        "import numpy\n",
        "\n",
        "# weighted kNN\n",
        "def w_knn(specimen, data, k):\n",
        "  # calculate the distance\n",
        "  data_copy = data.copy()\n",
        "  data_copy['distance_to_new'] = numpy.sqrt(\n",
        "    (specimen['petal length']-data['petal length'])**2\n",
        "    +(specimen['sepal length']-data['sepal length'])**2\n",
        "    +(specimen['petal width']-data['petal width'])**2\n",
        "    +(specimen['sepal width']-data['sepal width'])**2)\n",
        "  \n",
        "  # calculate the weights (remember, the weights are 1/d^2)\n",
        "  data_copy['weights'] = 1/(data_copy['distance_to_new']**2)\n",
        "\n",
        "  # find the closest k\n",
        "  sorted_data = data_copy.sort_values(['weights'], ascending = False) \n",
        "  top_k = sorted_data.iloc[0:k]\n",
        "\n",
        "  # use groupby to sum the weights of each species in the closest k\n",
        "  sum_of_weights_per_species = top_k.groupby(['species'])['weights'].sum()\n",
        "\n",
        "  sorted = sum_of_weights_per_species.sort_values(ascending=False)\n",
        "  return sorted.keys()[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDVhpKiagg6L"
      },
      "source": [
        "## Programming Exercise #2\n",
        "Normalize the predictor columns of the iris dataset using the Z-score\n",
        "- Note: you need a way to transform the new reading (the specimen) that you will make the prediction on so that the new one and the training data will all be on the same scale. How can you do that?\n",
        "\n",
        "Repeat your k-NN prediction code with the normalized data.\n",
        "- Does the value of k change the predictions?\n",
        "Compare using k=3, k=5 on each method (normalized and non-normalized).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbwGdS_ogyG9"
      },
      "source": [
        "data = pandas.read_csv('/content/drive/MyDrive/CS167Spring22/datasets/irisData.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qojXwY1gHByz"
      },
      "source": [
        "iris = {}\n",
        "iris['petal length'] = 5.1\n",
        "iris['sepal length'] = 7.2\n",
        "iris['petal width'] = 1.5\n",
        "iris['sepal width'] = 2.5\n",
        "\n",
        "print('not normalized knn: ', knn(iris,data, 3))\n",
        "print('not normalized w_knn: ', w_knn(iris,data, 3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code goes here\n",
        "# what are the means and standard deviations for petal_length, petal_width, sepal_length, sepal_width?"
      ],
      "metadata": {
        "id": "SWwk8m6Kt5Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# more of your code goes here\n",
        "\n",
        "norm_specimen = {}\n",
        "# update values in norm_specimin\n",
        "\n",
        "norm_data = data.copy()\n",
        "# update the columns in norm_data \n",
        "\n",
        "print('normalized knn: ', knn(norm_specimen,norm_data, 3))\n",
        "print('normalized w_knn: ', w_knn(norm_specimen,norm_data, 3))"
      ],
      "metadata": {
        "id": "p95463LyszDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}